# LatticeWeaver ML Notebooks

Suite completa de notebooks para entrenamiento, validaciÃ³n y optimizaciÃ³n de mini-IAs.

## ðŸ“š Notebooks Disponibles

### 01. Control Center (`01_Control_Center.ipynb`)
- Dashboard interactivo con estado del proyecto
- MenÃº principal de navegaciÃ³n
- Generador de reportes de progreso
- **Formato:** Jupyter Notebook (.ipynb)

### 02. Dataset Generation (`02_Dataset_Generation.py`)
- GeneraciÃ³n de problemas sintÃ©ticos
- Data augmentation (5x expansiÃ³n)
- PurificaciÃ³n y normalizaciÃ³n
- Train/val/test split
- **LÃ­neas:** 405

### 03. Training (`03_Training.py`)
- Entrenamiento automatizado con early stopping
- Monitoreo en tiempo real
- Checkpointing automÃ¡tico
- EvaluaciÃ³n en test set
- **LÃ­neas:** 374

### 04. Validation & Benchmarks (`04_Validation_Benchmarks.py`)
- ValidaciÃ³n de precisiÃ³n (MAE, RMSE, RÂ²)
- Benchmarks de velocidad de inferencia
- AnÃ¡lisis de overhead
- EstimaciÃ³n de speedup
- **LÃ­neas:** 470

### 05. Optimization (`05_Optimization.py`)
- CuantizaciÃ³n dinÃ¡mica (INT8)
- Export a ONNX
- ComparaciÃ³n pre/post optimizaciÃ³n
- **LÃ­neas:** 456

### 06. Model Explorer (`06_Model_Explorer.py`)
- Inferencia interactiva
- AnÃ¡lisis de sensibilidad
- InspecciÃ³n de arquitectura
- Feature importance
- **LÃ­neas:** 404

### 07. Error Analysis (`07_Error_Analysis.py`)
- AnÃ¡lisis de distribuciÃ³n de errores
- DetecciÃ³n de patrones
- Top 10 peores casos
- Sugerencias de mejora
- **LÃ­neas:** 457

### Utilidades (`ml_utils.py`)
- Clases compartidas por todos los notebooks
- ModelRegistry, Trainer, Validator, etc.
- **LÃ­neas:** 667

**Total:** ~3,233 lÃ­neas de cÃ³digo documentado

---

## ðŸš€ Uso RÃ¡pido

### En Google Colab

1. **Subir archivos:**
   ```python
   # En Colab, subir todos los archivos .py
   from google.colab import files
   uploaded = files.upload()
   ```

2. **Ejecutar notebooks en orden:**
   ```bash
   !python 02_Dataset_Generation.py
   !python 03_Training.py
   !python 04_Validation_Benchmarks.py
   !python 05_Optimization.py
   !python 06_Model_Explorer.py
   !python 07_Error_Analysis.py
   ```

3. **O convertir a notebooks:**
   ```bash
   !pip install jupytext
   !jupytext --to notebook 02_Dataset_Generation.py
   # Repetir para cada archivo
   ```

### Localmente

```bash
# Ejecutar directamente
python 02_Dataset_Generation.py
python 03_Training.py
# ...

# O convertir a notebooks
jupytext --to notebook *.py
jupyter notebook
```

---

## ðŸ“‹ Flujo de Trabajo Recomendado

```
1. Dataset Generation (20 min)
   â†“
2. Training (30-60 min)
   â†“
3. Validation & Benchmarks (10 min)
   â†“
4. Optimization (5 min)
   â†“
5. Model Explorer (interactivo)
   â†“
6. Error Analysis (5 min)
```

**Tiempo total:** ~1.5 horas por modelo

---

## âš™ï¸ ConfiguraciÃ³n

Todos los notebooks usan configuraciÃ³n centralizada. Editar al inicio de cada archivo:

```python
CONFIG = {
    'model_name': 'CostPredictor',
    'suite_name': 'costs_memoization',
    'batch_size': 32,
    'learning_rate': 1e-3,
    'num_epochs': 100,
    # ...
}
```

---

## ðŸ“Š MÃ©tricas Capturadas

Cada notebook genera mÃ©tricas detalladas:

- **Dataset Generation:** Tiempo, tamaÃ±o, factor de augmentation
- **Training:** Loss curves, learning rate, epoch time
- **Validation:** MAE, RMSE, RÂ², speedup, overhead
- **Optimization:** Size reduction, speedup, accuracy
- **Error Analysis:** Error distribution, patterns, suggestions

Todas las mÃ©tricas se exportan a:
- JSON (machine-readable)
- Markdown (human-readable)
- PNG (visualizaciones)

---

## ðŸ“ Estructura de Salida

```
/content/lattice-weaver/
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ csp/
â”‚       â”œâ”€â”€ train.pt
â”‚       â”œâ”€â”€ val.pt
â”‚       â”œâ”€â”€ test.pt
â”‚       â””â”€â”€ normalization_stats.json
â”œâ”€â”€ models/
â”‚   â””â”€â”€ costs_memoization/
â”‚       â”œâ”€â”€ CostPredictor_best.pt
â”‚       â”œâ”€â”€ CostPredictor_quantized.pt
â”‚       â””â”€â”€ CostPredictor.onnx
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ dataset_generation_*.md
â”‚   â”œâ”€â”€ training_*.md
â”‚   â”œâ”€â”€ validation_*.md
â”‚   â”œâ”€â”€ optimization_*.md
â”‚   â””â”€â”€ error_analysis_*.md
â””â”€â”€ logs/
    â””â”€â”€ errors/
```

---

## ðŸ› ï¸ Dependencias

```python
# Core
torch >= 1.10
numpy >= 1.20
matplotlib >= 3.3
seaborn >= 0.11

# Optional (para optimizaciÃ³n)
onnx >= 1.10
onnxruntime >= 1.10

# LatticeWeaver (si disponible)
lattice_weaver
```

InstalaciÃ³n en Colab:
```bash
!pip install torch numpy matplotlib seaborn onnx onnxruntime
```

---

## ðŸ”§ Troubleshooting

### Error: "Module not found"
```python
# Asegurarse de que ml_utils.py estÃ¡ en el mismo directorio
import sys
sys.path.insert(0, str(Path.cwd()))
```

### Error: "Dataset not found"
```python
# Ejecutar primero 02_Dataset_Generation.py
!python 02_Dataset_Generation.py
```

### Error: "CUDA out of memory"
```python
# Reducir batch size en CONFIG
CONFIG['batch_size'] = 16  # o menor
```

---

## ðŸ“– DocumentaciÃ³n Adicional

- **DocumentaciÃ³n completa:** `docs/suite_notebooks_documentacion_completa.md` (2,137 lÃ­neas)
- **AnÃ¡lisis ML:** `docs/ML_VISION.md`
- **Roadmap:** `README.md` (secciÃ³n ML)

---

## âœ… Checklist de ValidaciÃ³n

Antes de considerar un modelo listo para producciÃ³n:

- [ ] Dataset generado (> 1K samples)
- [ ] Modelo entrenado (val loss < 0.05)
- [ ] ValidaciÃ³n pasada (MAE < 0.2, RÂ² > 0.8)
- [ ] Overhead aceptable (< 5%)
- [ ] Speedup positivo (> 1.5x)
- [ ] Modelo optimizado (ONNX exportado)
- [ ] Errores analizados (< 10% large errors)

---

## ðŸŽ¯ PrÃ³ximos Pasos

1. **Entrenar suite completa** (6 modelos de Costos y MemoizaciÃ³n)
2. **Implementar suites adicionales** (RenormalizaciÃ³n, TDA, etc.)
3. **Integrar en LatticeWeaver** (MLAugmentedArcEngine)
4. **Benchmarks en problemas reales**
5. **Deployment en producciÃ³n**

---

## ðŸ“ž Soporte

Para preguntas o problemas:
1. Revisar documentaciÃ³n completa
2. Verificar logs de error en `/content/lattice-weaver/logs/`
3. Abrir issue en GitHub

---

**Creado:** 2025-10-13  
**VersiÃ³n:** 1.0  
**Autor:** LatticeWeaver ML Team

