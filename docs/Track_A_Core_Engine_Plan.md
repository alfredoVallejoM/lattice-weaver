# Track A: Core Engine - Plan de Implementaci√≥n Detallado

**Responsable:** Dev A (Core Developer)  
**Duraci√≥n:** 8 semanas  
**Dependencias:** Ninguna (track independiente)

---

## Objetivo

Resolver el Issue 1 de backtracking, implementar herramientas de trazado y an√°lisis del espacio de b√∫squeda, y crear la suite de experimentaci√≥n masiva.

---

## Semana 1-2: Resoluci√≥n Issue 1 + Gesti√≥n Incremental de Dominios + Paralelizaci√≥n Multiproceso (Completado)

### Tareas Completadas

#### 1.1 Resoluci√≥n del Issue 1 (Backtracking y Gesti√≥n de Dominios)

**Estado:** ‚úÖ **Completado y Validado**

Se ha resuelto el problema fundamental en la l√≥gica del `CSPSolver` relacionado con la gesti√≥n de dominios durante el backtracking. La soluci√≥n implic√≥ una refactorizaci√≥n significativa para asegurar que el `CSPSolver` gestione expl√≠citamente la copia y restauraci√≥n de los dominios del `ArcEngine` durante el backtracking, en lugar de depender √∫nicamente del TMS para la restauraci√≥n en cada paso. Esto ha mitigado la "re-actualizaci√≥n exponencial" de dominios y asegura la correcci√≥n funcional del algoritmo de b√∫squeda.

**Archivos modificados:**
- `lattice_weaver/arc_engine/csp_solver.py`
- `lattice_weaver/arc_engine/core.py`
- `lattice_weaver/arc_engine/tms.py`

**Validaci√≥n:** Los tests `test_csp_to_formal_verification.py` ahora pasan correctamente, confirmando que el `CSPSolver` encuentra soluciones v√°lidas para el problema de las N-Reinas.

#### 1.2 Implementaci√≥n de Gesti√≥n Incremental de Dominios con TMS

**Estado:** ‚úÖ **Completado y Validado**

Se ha extendido el `Truth Maintenance System (TMS)` para facilitar la gesti√≥n incremental de dominios. Aunque la restauraci√≥n directa de dominios en el backtracking se maneja ahora expl√≠citamente por el `CSPSolver`, el TMS sigue siendo fundamental para registrar las justificaciones de las eliminaciones, sentando las bases para futuras optimizaciones como el `conflict-directed backjumping`.

**Archivos modificados:**
- `lattice_weaver/arc_engine/tms.py`
- `lattice_weaver/arc_engine/core.py`
- `lattice_weaver/arc_engine/csp_solver.py`

**Validaci√≥n:** La funcionalidad del TMS ha sido exhaustivamente validada por su suite de tests unitarios (`test_tms.py`) y su integraci√≥n con el `ArcEngine` ha sido confirmada.

#### 1.3 Implementaci√≥n de Paralelizaci√≥n Multiproceso para Propagaci√≥n de Restricciones

**Estado:** ‚úÖ **Completado y Validado Funcionalmente**

Se ha implementado y validado una estrategia de paralelizaci√≥n multiproceso en `topological_parallel.py` para la propagaci√≥n de restricciones. Esto permite aprovechar la modularidad del espacio de c√≥mputo y distribuir la carga de trabajo entre m√∫ltiples n√∫cleos.

**Cambios clave:**
- **Refactorizaci√≥n de `Constraint`**: La clase `Constraint` ahora incluye `metadata` para informaci√≥n contextual y utiliza funciones de relaci√≥n nombradas y registradas globalmente, asegurando su serializabilidad.
- **`ArcEngine` Actualizado**: El `ArcEngine` construye y pasa el `metadata` a las restricciones y a la funci√≥n `revise_with_last_support`.
- **`topological_parallel.py` Refactorizado**: El m√≥dulo de paralelizaci√≥n multiproceso maneja correctamente la inicializaci√≥n de workers, la serializaci√≥n de restricciones y la fusi√≥n de dominios.
- **M√©todo `intersect` en `SetDomain`**: Se a√±adi√≥ un m√©todo `intersect` a `SetDomain` para facilitar la fusi√≥n de dominios en la paralelizaci√≥n.

**Archivos modificados/nuevos:**
- `lattice_weaver/arc_engine/constraints.py`
- `lattice_weaver/arc_engine/core.py`
- `lattice_weaver/arc_engine/ac31.py`
- `lattice_weaver/arc_engine/domains.py`
- `lattice_weaver/arc_engine/topological_parallel.py`
- `tests/unit/test_multiprocess_ac3_validation.py` (nuevo)

**Validaci√≥n:** Los tests `test_multiprocess_ac3_validation.py` confirman la correcci√≥n funcional de la implementaci√≥n paralela en comparaci√≥n con la secuencial para el problema de las N-Reinas.

### Entregable de la Fase Inicial

**Resumen de Logros:**
- ‚úÖ Issue 1 resuelto (backtracking y gesti√≥n de dominios).
- ‚úÖ Gesti√≥n incremental de dominios con TMS implementada.
- ‚úÖ Paralelizaci√≥n multiproceso para propagaci√≥n de restricciones implementada y funcionalmente validada.
- ‚úÖ C√≥digo base actualizado y tests pasando.

**M√©tricas (Funcionalidad):**
- `CSPSolver` ahora encuentra soluciones correctas para N-Reinas.
- `ArcEngine` propaga restricciones correctamente en modo secuencial y paralelo.
- `TMS` registra justificaciones de eliminaciones.

**Nota sobre Rendimiento:** Las pruebas de rendimiento en el entorno sandbox excedieron los l√≠mites de recursos, impidiendo la cuantificaci√≥n precisa de los speedups. Sin embargo, la base te√≥rica y la validaci√≥n funcional sugieren mejoras significativas en entornos con recursos dedicados.

---

## Pr√≥ximas Fases de Desarrollo (Actualizado)

### Semana 1-2: SearchSpaceTracer (Pendiente)

**Objetivo:** Implementar herramientas de trazado y an√°lisis del espacio de b√∫squeda para monitorear el comportamiento del `CSPSolver`.

**Tareas:**
- Implementar `SearchSpaceTracer` para registrar eventos de b√∫squeda (asignaciones, backtracks, propagaciones).
- Desarrollar funcionalidades de exportaci√≥n a CSV/JSON y estad√≠sticas agregadas.

**Archivos a crear/modificar:**
- `lattice_weaver/arc_weaver/tracing.py` (nuevo)
- Integraci√≥n en `ArcEngine` y `CSPSolver`.

**Tests a crear:**
- `test_tracer_records_assignments()`
- `test_tracer_records_backtracks()`
- `test_tracer_csv_export()`
- `test_tracer_json_export()`
- `test_tracer_statistics()`
- `test_tracer_disabled_no_overhead()`

**Checkpoint:** Tracer funcional, exportaci√≥n CSV/JSON, overhead <5%.

---

### Semana 3-4: SearchSpaceVisualizer (Pendiente)

**Objetivo:** Crear herramientas de visualizaci√≥n para el espacio de b√∫squeda y la evoluci√≥n de dominios.

**Tareas:**
- Implementar `SearchSpaceVisualizer` para cargar traces y generar visualizaciones interactivas (√°rbol de b√∫squeda, evoluci√≥n de dominios, l√≠nea de tiempo).
- Crear ejemplos y documentaci√≥n para el uso del visualizador.

**Archivos a crear/modificar:**
- `lattice_weaver/arc_weaver/visualization.py` (nuevo)

**Tests a crear:**
- `test_visualizer_loads_trace()`
- `test_plot_search_tree_generates_html()`
- `test_plot_domain_evolution()`
- `test_plot_timeline()`
- `test_generate_full_report()`

**Checkpoint:** Visualizaciones HTML generadas correctamente.

---

### Semana 5-6: ExperimentRunner (Miner√≠a Masiva) (Pendiente)

**Objetivo:** Implementar una herramienta para la ejecuci√≥n masiva de experimentos y an√°lisis de rendimiento.

**Tareas:**
- Implementar `ExperimentRunner` para ejecutar b√∫squedas en grilla de par√°metros y algoritmos en paralelo.
- Crear suites de experimentos predefinidos para an√°lisis de escalabilidad y densidad.

**Archivos a crear/modificar:**
- `lattice_weaver/benchmarks/experiment_runner.py` (nuevo)
- `lattice_weaver/benchmarks/experiment_suites.py` (nuevo)

**Tests a crear:**
- `test_experiment_runner_grid_search()`
- `test_experiment_runner_parallel_execution()`
- `test_experiment_runner_timeout_handling()`

**Checkpoint:** ExperimentRunner funcional, ejecuci√≥n paralela.

---

### Semana 7-8: Integraci√≥n y Optimizaci√≥n Final (Pendiente)

**Objetivo:** Optimizar el overhead del tracer, crear un dashboard integrado y finalizar la documentaci√≥n.

**Tareas:**
- Optimizar el overhead del tracer (lazy evaluation, sampling, buffer de eventos).
- Crear un dashboard simple (Flask app) para visualizaci√≥n en tiempo real y comparaci√≥n de traces.
- Finalizar la documentaci√≥n (`CORE_ENGINE_GUIDE.md`, `EXPERIMENTATION_GUIDE.md`) y ejemplos.

**Archivos a crear/modificar:**
- `lattice_weaver/dashboard/app.py` (nuevo)

**Checkpoint:** Documentaci√≥n completa, ejemplos ejecutables, dashboard funcional.

---

## Puntos de Sincronizaci√≥n con Otros Tracks (Actualizado)

### Sync Point 1 (Fase Inicial Completada)
**Con Track D (Inference Engine):**
- **Estado:** ‚úÖ **Completado**. El formato de las soluciones del `CSPSolver` y la estructura de los dominios son estables y pueden ser utilizados por el Inference Engine para generar traces sint√©ticos o analizar soluciones.

### Sync Point 2 (Pendiente - Despu√©s de SearchSpaceVisualizer)
**Con Track E (Web App):**
- Definir API REST para subir traces y obtener visualizaciones.

### Sync Point 3 (Pendiente - Despu√©s de ExperimentRunner)
**Con Track C (Problem Families):**
- Integrar generadores de familias de problemas en ExperimentRunner.

### Sync Point 4 (Pendiente - Final Track A)
**Con todos los tracks:**
- Integraci√≥n final y validaci√≥n cruzada.

---

## Riesgos y Mitigaciones (Actualizado)

### Riesgo 1: Overhead del Tracer
**Mitigaci√≥n:** Implementar sampling y lazy evaluation desde el inicio (Pendiente de implementaci√≥n).

### Riesgo 2: Rendimiento de la Paralelizaci√≥n
**Mitigaci√≥n:** La implementaci√≥n de la paralelizaci√≥n multiproceso ya ha sido validada funcionalmente. La cuantificaci√≥n del rendimiento se realizar√° en un entorno con recursos dedicados.

---

## Estado General del Track A: Core Engine

**Estado:** üöß **EN PROGRESO (Fase Inicial Completada)**

La fase inicial del Track A, que incluye la resoluci√≥n de problemas cr√≠ticos de backtracking, la gesti√≥n incremental de dominios con TMS y la implementaci√≥n de la paralelizaci√≥n multiproceso, ha sido completada con √©xito. El c√≥digo base es ahora m√°s robusto y eficiente, sentando las bases para las pr√≥ximas fases de desarrollo centradas en el trazado, visualizaci√≥n y experimentaci√≥n masiva.

### Tareas

#### 1.1 Implementar Soluci√≥n H√≠brida al Issue 1 (3 d√≠as)

**Archivos a modificar:**
- `lattice_weaver/arc_weaver/adaptive_consistency.py`

**Cambios:**
```python
class AdaptiveConsistencyEngine:
    def __init__(self, ..., propagation_strategy='selective'):
        self.propagation_strategy = propagation_strategy
        
    def _propagate_assignment(self, var, value):
        if self.propagation_strategy == 'selective':
            # Solo propagar a vecinos directos
            neighbors = self.cg.get_neighbors(var)
            return self._ac3_solver.enforce_arc_consistency(
                variables=neighbors
            )
        elif self.propagation_strategy == 'full':
            # AC-3 completo (comportamiento actual)
            return self._ac3_solver.enforce_arc_consistency()
```

**Tests a crear:**
- `test_selective_propagation_nqueens_4()`
- `test_selective_propagation_nqueens_8()`
- `test_full_vs_selective_comparison()`

**Checkpoint 1.1:** Tests pasando, N-Reinas n=8 resuelve en <1s

---

#### 1.2 Implementar SearchSpaceTracer (4 d√≠as)

**Archivo nuevo:**
- `lattice_weaver/arc_weaver/tracing.py` (‚âà500 l√≠neas)

**Clases:**
```python
@dataclass
class SearchEvent:
    timestamp: float
    event_type: str  # 'assignment', 'backtrack', 'propagation', etc.
    variable: Optional[str]
    value: Optional[Any]
    domains_snapshot: Dict[str, Set]
    metadata: Dict[str, Any]

class SearchSpaceTracer:
    def __init__(self, enabled: bool = True):
        self.enabled = enabled
        self.events: List[SearchEvent] = []
        
    def record_assignment(self, var, value, domains):
        if not self.enabled:
            return
        self.events.append(SearchEvent(...))
        
    def record_backtrack(self, var, domains):
        ...
        
    def record_propagation(self, affected_vars, domains):
        ...
        
    def to_csv(self, path: str):
        """Exportar a CSV para an√°lisis"""
        
    def to_json(self, path: str):
        """Exportar a JSON para visualizaci√≥n"""
        
    def get_statistics(self) -> Dict:
        """Estad√≠sticas agregadas"""
        return {
            'total_assignments': ...,
            'total_backtracks': ...,
            'avg_domain_size': ...,
            'branching_factor': ...
        }
```

**Integraci√≥n en ACE:**
```python
class AdaptiveConsistencyEngine:
    def __init__(self, ..., tracer: Optional[SearchSpaceTracer] = None):
        self.tracer = tracer or SearchSpaceTracer(enabled=False)
        
    def _backtrack_search(self, ...):
        var = self._select_variable()
        for value in domain:
            self.tracer.record_assignment(var, value, self.cg.domains)
            # ... resto del c√≥digo
            if not consistent:
                self.tracer.record_backtrack(var, self.cg.domains)
```

**Tests a crear:**
- `test_tracer_records_assignments()`
- `test_tracer_records_backtracks()`
- `test_tracer_csv_export()`
- `test_tracer_json_export()`
- `test_tracer_statistics()`
- `test_tracer_disabled_no_overhead()`

**Checkpoint 1.2:** Tracer funcional, exportaci√≥n CSV/JSON, overhead <5%

---

### Entregable Semana 2

**Archivos:**
- `adaptive_consistency.py` (modificado)
- `tracing.py` (nuevo)
- `test_issue1_resolution.py` (nuevo, 10 tests)
- `test_tracing.py` (nuevo, 15 tests)

**Documentaci√≥n:**
- `docs/TRACING_GUIDE.md` - Gu√≠a de uso del tracer

**Validaci√≥n:**
```bash
pytest tests/unit/test_issue1_resolution.py -v
pytest tests/unit/test_tracing.py -v
python examples/trace_nqueens_8.py  # Genera trace.csv
```

---

## Semana 3-4: SearchSpaceVisualizer

### Tareas

#### 2.1 Implementar Visualizador (5 d√≠as)

**Archivo nuevo:**
- `lattice_weaver/arc_weaver/visualization.py` (‚âà400 l√≠neas)

**Clases:**
```python
class SearchSpaceVisualizer:
    def __init__(self, trace_file: str):
        self.events = self._load_trace(trace_file)
        
    def plot_search_tree(self, output='search_tree.html'):
        """√Årbol de b√∫squeda interactivo con Plotly"""
        
    def plot_domain_evolution(self, variables=None, output='domains.html'):
        """Evoluci√≥n de dominios en el tiempo"""
        
    def plot_timeline(self, output='timeline.html'):
        """L√≠nea de tiempo de eventos"""
        
    def generate_report(self, output_dir='report/'):
        """Reporte HTML completo"""
```

**Implementaci√≥n de plot_search_tree:**
```python
def plot_search_tree(self, output='search_tree.html'):
    import plotly.graph_objects as go
    
    # Construir √°rbol desde eventos
    nodes = []
    edges = []
    current_path = []
    
    for event in self.events:
        if event.event_type == 'assignment':
            node_id = len(nodes)
            nodes.append({
                'id': node_id,
                'label': f"{event.variable}={event.value}",
                'depth': len(current_path)
            })
            if current_path:
                edges.append((current_path[-1], node_id))
            current_path.append(node_id)
            
        elif event.event_type == 'backtrack':
            current_path.pop()
    
    # Crear figura con Plotly
    fig = go.Figure(data=[
        go.Scatter(
            x=[node['depth'] for node in nodes],
            y=list(range(len(nodes))),
            mode='markers+text',
            text=[node['label'] for node in nodes],
            ...
        )
    ])
    
    fig.write_html(output)
```

**Tests a crear:**
- `test_visualizer_loads_trace()`
- `test_plot_search_tree_generates_html()`
- `test_plot_domain_evolution()`
- `test_plot_timeline()`
- `test_generate_full_report()`

**Checkpoint 2.1:** Visualizaciones HTML generadas correctamente

---

#### 2.2 Crear Ejemplos y Documentaci√≥n (2 d√≠as)

**Ejemplos a crear:**
- `examples/trace_and_visualize_nqueens.py`
- `examples/compare_algorithms_visually.py`
- `examples/analyze_backtracking_patterns.py`

**Documentaci√≥n:**
- `docs/VISUALIZATION_GUIDE.md`

**Checkpoint 2.2:** Ejemplos ejecutables, documentaci√≥n completa

---

### Entregable Semana 4

**Archivos:**
- `visualization.py` (nuevo)
- `test_visualization.py` (nuevo, 12 tests)
- 3 ejemplos ejecutables
- 2 gu√≠as de documentaci√≥n

**Validaci√≥n:**
```bash
pytest tests/unit/test_visualization.py -v
python examples/trace_and_visualize_nqueens.py
# Abrir report/index.html en navegador
```

---

## Semana 5-6: ExperimentRunner (Miner√≠a Masiva)

### Tareas

#### 3.1 Implementar ExperimentRunner (6 d√≠as)

**Archivo nuevo:**
- `lattice_weaver/benchmarks/experiment_runner.py` (‚âà600 l√≠neas)

**Clases:**
```python
@dataclass
class ExperimentConfig:
    problem_type: str
    param_grid: Dict[str, List[Any]]
    algorithms: List[str]
    timeout: float
    repetitions: int

class ExperimentRunner:
    def __init__(self, config: ExperimentConfig, n_jobs: int = -1):
        self.config = config
        self.n_jobs = n_jobs
        
    def run_grid_search(self) -> pd.DataFrame:
        """Ejecutar grid search completo"""
        from concurrent.futures import ProcessPoolExecutor, TimeoutError
        
        # Generar todas las combinaciones
        experiments = self._generate_experiments()
        
        # Ejecutar en paralelo
        with ProcessPoolExecutor(max_workers=self.n_jobs) as executor:
            futures = [
                executor.submit(self._run_single_experiment, exp)
                for exp in experiments
            ]
            
            results = []
            for future in as_completed(futures):
                try:
                    result = future.result(timeout=self.config.timeout)
                    results.append(result)
                except TimeoutError:
                    results.append({'status': 'timeout', ...})
                    
        return pd.DataFrame(results)
        
    def _run_single_experiment(self, exp_config):
        """Ejecutar un experimento individual"""
        problem = self._create_problem(exp_config)
        solver = self._create_solver(exp_config)
        
        start = time.time()
        stats = solver.solve(problem)
        elapsed = time.time() - start
        
        return {
            'problem_type': exp_config['problem_type'],
            'algorithm': exp_config['algorithm'],
            **exp_config['params'],
            'time': elapsed,
            'nodes': stats.nodes_explored,
            'backtracks': stats.backtracks,
            'success': stats.solutions_found > 0
        }
        
    def visualize_results(self, df: pd.DataFrame, output_dir='results/'):
        """Generar visualizaciones de resultados"""
        # Heatmaps, scatter plots, etc.
```

**Tests a crear:**
- `test_experiment_runner_grid_search()`
- `test_experiment_runner_parallel_execution()`
- `test_experiment_runner_timeout_handling()`
- `test_experiment_runner_csv_export()`
- `test_experiment_runner_visualization()`

**Checkpoint 3.1:** ExperimentRunner funcional, ejecuci√≥n paralela

---

#### 3.2 Crear Suite de Experimentos Predefinidos (2 d√≠as)

**Archivo nuevo:**
- `lattice_weaver/benchmarks/experiment_suites.py`

```python
def nqueens_scalability_suite() -> ExperimentConfig:
    """Suite para analizar escalabilidad en N-Reinas"""
    return ExperimentConfig(
        problem_type='nqueens',
        param_grid={
            'n': [4, 6, 8, 10, 12, 14, 16],
            'propagation_strategy': ['selective', 'full']
        },
        algorithms=['ace', 'backtracking', 'forward_checking'],
        timeout=60.0,
        repetitions=5
    )

def graph_coloring_density_suite() -> ExperimentConfig:
    """Suite para analizar impacto de densidad en coloreo"""
    return ExperimentConfig(
        problem_type='graph_coloring',
        param_grid={
            'n_nodes': [10, 20, 30],
            'density': [0.3, 0.5, 0.7, 0.9],
            'n_colors': [3, 4, 5]
        },
        algorithms=['ace', 'backtracking'],
        timeout=30.0,
        repetitions=3
    )
```

**Checkpoint 3.2:** Suites predefinidas, f√°ciles de ejecutar

---

### Entregable Semana 6

**Archivos:**
- `experiment_runner.py` (nuevo)
- `experiment_suites.py` (nuevo)
- `test_experiment_runner.py` (nuevo, 15 tests)

**Ejemplo de uso:**
```python
from lattice_weaver.benchmarks import ExperimentRunner, nqueens_scalability_suite

runner = ExperimentRunner(nqueens_scalability_suite(), n_jobs=8)
results = runner.run_grid_search()
results.to_csv('nqueens_scalability.csv')
runner.visualize_results(results, output_dir='results/')
```

**Validaci√≥n:**
```bash
pytest tests/unit/test_experiment_runner.py -v
python examples/run_scalability_experiment.py
# Genera nqueens_scalability.csv y visualizaciones
```

---

## Semana 7-8: Integraci√≥n y Optimizaci√≥n

### Tareas

#### 4.1 Optimizar Overhead del Tracer (2 d√≠as)

**Objetivo:** Reducir overhead a <2% cuando habilitado

**T√©cnicas:**
- Lazy evaluation de snapshots
- Sampling configurable (grabar 1 de cada N eventos)
- Buffer de eventos en memoria

**Checkpoint 4.1:** Benchmark muestra overhead <2%

---

#### 4.2 Crear Dashboard Integrado (3 d√≠as)

**Archivo nuevo:**
- `lattice_weaver/dashboard/app.py` (Flask app simple)

**Funcionalidad:**
- Subir archivo de trace
- Visualizar en tiempo real
- Comparar m√∫ltiples traces
- Exportar reportes

**Checkpoint 4.2:** Dashboard funcional localmente

---

#### 4.3 Documentaci√≥n Final y Ejemplos (3 d√≠as)

**Documentos a crear:**
- `docs/CORE_ENGINE_GUIDE.md` - Gu√≠a completa
- `docs/EXPERIMENTATION_GUIDE.md` - Gu√≠a de experimentaci√≥n
- `CHANGELOG_v4.2.md` - Changelog detallado

**Ejemplos a crear:**
- `examples/full_workflow_nqueens.py` - Workflow completo
- `examples/compare_strategies.py` - Comparaci√≥n de estrategias
- `examples/massive_experiment.py` - Experimento masivo

**Checkpoint 4.3:** Documentaci√≥n completa, ejemplos ejecutables

---

### Entregable Semana 8 (Final Track A)

**Resumen de Logros:**
- ‚úÖ Issue 1 resuelto (N-Reinas n=8 en <1s)
- ‚úÖ SearchSpaceTracer funcional (overhead <2%)
- ‚úÖ SearchSpaceVisualizer con reportes HTML
- ‚úÖ ExperimentRunner para miner√≠a masiva
- ‚úÖ Dashboard simple para visualizaci√≥n
- ‚úÖ Documentaci√≥n completa
- ‚úÖ 52+ tests nuevos

**Archivos entregados:**
- 5 m√≥dulos Python (‚âà2,000 l√≠neas)
- 52+ tests unitarios
- 6+ ejemplos ejecutables
- 4 gu√≠as de documentaci√≥n
- Dashboard Flask

**M√©tricas:**
- Speedup N-Reinas: 10-20x
- Overhead tracer: <2%
- Cobertura tests: >90%
- Experimentos paralelos: 8x speedup con 8 cores

---

## Puntos de Sincronizaci√≥n con Otros Tracks

### Sync Point 1 (Semana 2)
**Con Track D (Inference Engine):**
- Compartir formato de trace para que el inference engine pueda generar traces sint√©ticos

### Sync Point 2 (Semana 4)
**Con Track E (Web App):**
- Definir API REST para subir traces y obtener visualizaciones

### Sync Point 3 (Semana 6)
**Con Track C (Problem Families):**
- Integrar generadores de familias de problemas en ExperimentRunner

### Sync Point 4 (Semana 8)
**Con todos los tracks:**
- Integraci√≥n final y validaci√≥n cruzada

---

## Riesgos y Mitigaciones

### Riesgo 1: Overhead del Tracer
**Mitigaci√≥n:** Implementar sampling y lazy evaluation desde el inicio

### Riesgo 2: Escalabilidad de Visualizaciones
**Mitigaci√≥n:** Limitar n√∫mero de eventos visualizados, ofrecer agregaci√≥n

### Riesgo 3: Timeout en Experimentos Masivos
**Mitigaci√≥n:** Timeout por experimento, manejo robusto de excepciones

---

## Checklist de Completitud

- [ ] Issue 1 resuelto (N-Reinas n=8 <1s)
- [ ] SearchSpaceTracer implementado
- [ ] Exportaci√≥n CSV/JSON funcional
- [ ] SearchSpaceVisualizer implementado
- [ ] Reportes HTML generados
- [ ] ExperimentRunner implementado
- [ ] Ejecuci√≥n paralela funcional
- [ ] Suites predefinidas creadas
- [ ] Dashboard Flask funcional
- [ ] 52+ tests pasando
- [ ] Documentaci√≥n completa
- [ ] Ejemplos ejecutables
- [ ] Overhead <2%
- [ ] Cobertura >90%

---

**Estado:** ‚úÖ PLAN COMPLETO Y DETALLADO

